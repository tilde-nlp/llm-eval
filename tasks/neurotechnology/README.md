
The original paper [available here](https://arxiv.org/pdf/2408.12963) reports an average accuracy of YYYY using [neurotechnology/Lt-Llama-2-7b-hf](https://huggingface.co/neurotechnology/Lt-Llama-2-7b-hf) model.


| Dataset                                                                              | [original paper](https://arxiv.org/pdf/2408.12963) | Our accuracy |Our normalized accuracy | n-shot   |
|--------------------------------------------------------------------------------------|----------------------------------------------------|--------------|-------------|----------|
 [lt_gsm8k](https://huggingface.co/datasets/neurotechnology/lt_gsm8k)                 | 0.0                                              | 0.0168 (flexible match)     | ----    | 5 |
| [lithuanian-qa-v1](https://huggingface.co/datasets/neurotechnology/lithuanian-qa-v1) | ---                                               | ----     | ----    | ---- |
| [lt_hellaswag](https://huggingface.co/datasets/neurotechnology/lt_hellaswag)         | 0.3250                                            | 0.3221       | 0.3647  | 10       |
| [lt_thruthful_qa](https://huggingface.co/datasets/neurotechnology/lt_thruthful_qa) (mc_2)   | 0.4138                                              | 0.4338     | ----    | 0 |
| [lt_arc](https://huggingface.co/datasets/neurotechnology/lt_arc) (easy)                    | 0.4318                                              | 0.4175     | 0.4137    | 25 |
| [lt_winogrande](https://huggingface.co/datasets/neurotechnology/lt_winogrande)      | 0.5367                                               | 0.5217     | ----    | 5 |

